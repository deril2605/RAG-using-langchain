{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MODEL = \"gpt-4o\" # chat model\n",
    "# MODEL = \"llama3\" # completion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(Wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you smile! Do you want to hear another one?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"gpt\" in MODEL:\n",
    "    parser = StrOutputParser()\n",
    "    model = ChatOpenAI(model=MODEL, api_key=OPEN_API_KEY)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    INDEX = \"open-source-rag-index\"\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)\n",
    "    INDEX = \"open-source-rag-index-llama3\"\n",
    "\n",
    "chain = model | parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='● Leveraged Airflow DAGs  for creating seamless ETL pipeline to automate and optimize data extraction from 5 distinct AWS S3  \\nsources  \\n● Incorporated  data preprocessing techniques like  clean ing, normalization, and transformation for over 50,000 records into Azure \\nCosmos DB  \\n● Automated the generation of reports using Power  BI and optimized with DAX queries  to reduc e report preparation time by 30%  \\nAdvanced Labor Data Analytics and Visualization  | Python,  Alteryx,  Grafana, MySQL                                                                Nov 2022  \\n● Engineered  Python  scripts  for API integration, fetch ing 30+ years of labour statistics JSON data from BLS API to drive \\ncomprehensive economic trend analysis  \\n● Developed a custom Alteryx plugin in Python to adeptly import, cleanse, and manipulate over 100,000 rows of data  \\n● Performed data analysis and visualization of labor statistics, highlighting economic trends and patterns using Grafana . \\nPUBLICATIONS  \\n● Co-authored a research paper titled \" Multiple Disease Prognostication Based On Symptoms Using Machine Learning \\nTechniques ,\" presented at the International Conference on Automation, Computing and Communication 2022 (ICACC -2022)', metadata={'source': 'Pramita Data Analyst Resume.pdf', 'page': 0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_loader = PyPDFLoader(\"Pramita Data Analyst Resume.pdf\")\n",
    "pages = pdf_loader.load_and_split()\n",
    "pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Here is some context\\n\\nQuestion: Here is a question\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\":\"I am deril\",\n",
    "    \"question\": \"what's my last name?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    pages, embedding=embeddings, index_name=INDEX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can answer that! According to the context, you have at least 4 academic projects:\\n\\n1. IMDb Movies Data Analysis\\n2. Multiple Disease Prediction System - Modern Shaman\\n3. Food Delivery Management System\\n4. Advanced Labor Data Analytics and Visualization (this one seems to be a part of your professional experience rather than an academic project)\\n\\nThere might be more projects mentioned in the context, but these 4 are explicitly listed as academic projects.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"How many projects do i have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, I can see that you have mentioned several academic projects and professional experience. Here are the specific project mentions:\\n\\n1. IMDB Movies Data Analysis\\n2. Multiple Disease Prediction System - Modern Shaman\\n3. Food Delivery Management System\\n\\nThese three are explicitly mentioned as projects in your resume.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": itemgetter(\"question\") | pinecone.as_retriever(), \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke({\"question\":\"How many projects do i have?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('machine-learning-tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31384ce3dd6bc2c85be3c3d887d32a02f47760f0703449b13d0f58d482b7108e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
